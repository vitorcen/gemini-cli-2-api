import { describe, test, expect } from 'vitest';
import { POST } from '../utils/httpClient';
import { OPENAI_CONVERSATION_REQUEST, OPENAI_SYSTEM_REQUEST } from '../fixtures/requests';

describe('OpenAI - Multi-turn Conversations', () => {

  test('should preserve assistant messages in context', async () => {
    console.log('\nğŸ“ Testing multi-turn conversation...');
    console.log('Messages:', JSON.stringify(OPENAI_CONVERSATION_REQUEST.messages, null, 2));

    const response = await POST('/v1/chat/completions', OPENAI_CONVERSATION_REQUEST);

    console.log('Response:', response.data.choices[0].message.content);
    console.log('Usage:', response.data.usage);

    expect(response.status).toBe(200);
    expect(response.data.choices[0].message.content).toBeDefined();

    // å…³é”®éªŒè¯ï¼šæ¨¡å‹åº”è¯¥è®°ä½åå­—æ˜¯ Alice
    const content = response.data.choices[0].message.content.toLowerCase();
    const hasAlice = content.includes('alice');

    console.log(hasAlice ? 'âœ… Context preserved - found "Alice"' : 'âŒ Context lost - "Alice" not found');
    expect(hasAlice).toBe(true);
  });

  test('should handle system messages', async () => {
    console.log('\nğŸ“ Testing system message...');
    console.log('System:', OPENAI_SYSTEM_REQUEST.messages[0].content);

    const response = await POST('/v1/chat/completions', OPENAI_SYSTEM_REQUEST);

    console.log('Response:', response.data.choices[0].message.content);

    expect(response.status).toBe(200);

    // æµ·ç›—åº”è¯¥è¯´ "Arrr"
    const content = response.data.choices[0].message.content.toLowerCase();
    const hasPirateSpeak = content.includes('arr') || content.includes('ahoy') || content.includes('matey');

    console.log(hasPirateSpeak ? 'âœ… System prompt working' : 'âš ï¸  No pirate speak detected');
    // æ³¨æ„ï¼šè¿™ä¸ªå¯èƒ½ä¸æ€»æ˜¯é€šè¿‡ï¼Œå› ä¸ºæ¨¡å‹ä¸ä¸€å®šæ¯æ¬¡éƒ½è¯´ arrr
  });
});
